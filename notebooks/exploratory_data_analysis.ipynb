{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804a6b61",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This notebook analyzes the Power Combined and HPC Kernel Events datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ff84e",
   "metadata": {},
   "source": [
    "## Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "data_dir = Path('../data/raw')\n",
    "power_path = data_dir / 'Power.csv'\n",
    "hpc_path = data_dir / 'HPC.csv'\n",
    "\n",
    "# Check if files exist\n",
    "if not power_path.exists() or not hpc_path.exists():\n",
    "    # Try alternative paths\n",
    "    data_dir = Path('../datasets')\n",
    "    power_path = data_dir / 'Power.csv'\n",
    "    hpc_path = data_dir / 'HPC.csv'\n",
    "\n",
    "# Load datasets\n",
    "try:\n",
    "    power_df = pd.read_csv(power_path)\n",
    "    print(f\"Power dataset loaded with shape: {power_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Power dataset not found at {power_path}\")\n",
    "    power_df = None\n",
    "\n",
    "try:\n",
    "    hpc_df = pd.read_csv(hpc_path)\n",
    "    print(f\"HPC dataset loaded with shape: {hpc_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"HPC dataset not found at {hpc_path}\")\n",
    "    hpc_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047b624",
   "metadata": {},
   "source": [
    "## Power Combined Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if power_df is not None:\n",
    "    # Basic info\n",
    "    print(\"First 5 rows:\")\n",
    "    display(power_df.head())\n",
    "    \n",
    "    print(\"\\nBasic info:\")\n",
    "    power_df.info()\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(power_df.isnull().sum())\n",
    "    \n",
    "    print(\"\\nSummary statistics:\")\n",
    "    display(power_df.describe())\n",
    "else:\n",
    "    print(\"Power dataset not available for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if power_df is not None and 'Attack-Group' in power_df.columns:\n",
    "    # Class distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='Attack-Group', data=power_df)\n",
    "    plt.title('Attack Group Distribution')\n",
    "    plt.xlabel('Attack Group')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae160362",
   "metadata": {},
   "outputs": [],
   "source": [
    "if power_df is not None:\n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    numeric_cols = power_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlation = power_df[numeric_cols].corr()\n",
    "    sns.heatmap(correlation, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad4e74",
   "metadata": {},
   "source": [
    "## HPC Kernel Events Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hpc_df is not None:\n",
    "    # Basic info\n",
    "    print(\"First 5 rows:\")\n",
    "    display(hpc_df.head())\n",
    "    \n",
    "    print(\"\\nBasic info:\")\n",
    "    hpc_df.info()\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(hpc_df.isnull().sum())\n",
    "    \n",
    "    print(\"\\nSummary statistics:\")\n",
    "    display(hpc_df.describe())\n",
    "else:\n",
    "    print(\"HPC dataset not available for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0dc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hpc_df is not None and 'Scenario' in hpc_df.columns:\n",
    "    # Top scenarios\n",
    "    scenario_counts = hpc_df['Scenario'].value_counts().head(10)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=scenario_counts.index, y=scenario_counts.values)\n",
    "    plt.title('Top 10 Scenarios')\n",
    "    plt.xlabel('Scenario')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hpc_df is not None:\n",
    "    # Apply PCA\n",
    "    numeric_cols = hpc_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if len(numeric_cols) > 2:\n",
    "        # Standardize\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(hpc_df[numeric_cols])\n",
    "        \n",
    "        # PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "        plt.title('PCA: First Two Principal Components')\n",
    "        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Total variance explained by 2 components: {sum(pca.explained_variance_ratio_):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983d9df",
   "metadata": {},
   "source": [
    "## Feature Fusion Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d70974",
   "metadata": {},
   "outputs": [],
   "source": [
    "if power_df is not None and hpc_df is not None:\n",
    "    print(f\"Power dataset features: {power_df.shape[1]}, samples: {power_df.shape[0]}\")\n",
    "    print(f\"HPC dataset features: {hpc_df.shape[1]}, samples: {hpc_df.shape[0]}\")\n",
    "    print(\"\\nPossible feature fusion approaches:\")\n",
    "    print(\"1. Feature concatenation\")\n",
    "    print(\"2. Weighted feature fusion\")\n",
    "    print(\"3. PCA-based dimensionality reduction\")\n",
    "else:\n",
    "    print(\"Both datasets are needed for feature fusion analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34beda8b",
   "metadata": {},
   "source": [
    "## Preprocessing Steps Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651e6ed",
   "metadata": {},
   "source": [
    "### Power Combined Dataset:\n",
    "1. Handle missing values\n",
    "2. Rename attack labels ('host-attack' → 'Other', 'none' → 'Begin', 'recon' → 'Recon')\n",
    "3. Encode categorical features ('Attack-Group', 'State', 'interface', 'Label')\n",
    "4. Apply SMOTE for class balancing\n",
    "5. Apply StandardScaler to normalize feature ranges\n",
    "\n",
    "### HPC Kernel Events Dataset:\n",
    "1. Handle missing values\n",
    "2. Filter out specific Scenario values ('writeback:writeback_write_inode_start', '0', 0.0)\n",
    "3. Rename 'Cryptojacking' to 'Other' (if the column exists)\n",
    "4. Apply StandardScaler to normalize numeric features\n",
    "5. Apply PCA for dimensionality reduction\n",
    "6. Encode the 'Scenario' target label"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
